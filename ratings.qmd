# Ratings

## Core Rating Categories (60% of Total Rating)

### 1. Protocol Value Capture (30%)
A. Network Effect Metrics
- Daily Active Users (DAUs)
- Total Value Locked (TVL)
- Transaction volume
- Fee revenue generated
- Protocol revenue retained

B. Value Accrual Mechanisms
- Token economics design
- Fee distribution model
- Staking mechanisms
- Burns and supply dynamics

C. Ozempic Network Effects 
- Value extraction efficiency from L1
    - Transaction fee capture rate
    - User migration metrics from L1
    - TVL migration patterns
    - Gas savings versus L1
- L1-L2 Value Dynamics
    - Sequencer revenue distribution
    - MEV capture and distribution
    - Bridge volume and efficiency
    - Settlement layer costs
- Sustainable Value Creation
    - Net new users versus L1 migration
    - Ecosystem-specific applications
    - Novel transaction types impossible on L1
    - Cross-L2 interoperability metrics

### 2. Protocol Security & Risk Assessment (30%)
A. Smart Contract Security
- Audit history and quality
- Bug bounty program effectiveness
- Historical vulnerability incidents
- Code complexity metrics
- Upgrade mechanism security
- Testing coverage

B. Network Security
- Consensus mechanism robustness
- MEV exposure and protection measures
- Node distribution
- Network attack resistance
- Cross-chain bridge security
- Oracle dependency and security

C. L1 Dependency Risks
- Settlement layer congestion exposure
- Bridge security and liquidity depth
- L1 fee market correlation
- Sequencer centralization risk
- Value extraction sustainability

## Risk Categories (40% of Total Rating)

### 1. Technical Risk Assessment (15%)
A. Smart Contract Vulnerabilities
- Code audit findings severity
- Time-tested deployment
- Complexity of interactions
- Dependencies on external protocols
- Historical incident analysis

B. Network Level Risks
- MEV exposure metrics
- Network partition resistance
- Node centralization factors
- Infrastructure dependencies
- Cross-chain vulnerability exposure

C. Key Management & Wallet Security
- Multi-sig implementation
- Key generation processes
- Hardware security modules usage
- Social recovery mechanisms
- Access control systems

### 2. Economic Risk Assessment (10%)
A. Market Dynamics
- Liquidity concentration
- Price impact resistance
- Collateral quality
- Market manipulation resistance

B. Economic Model Vulnerabilities
- Game theory attack vectors
- Incentive alignment analysis
- Economic exploit resistance
- Stress test scenarios
- Flash loan attack surface

### 3. Operational Risk Assessment (10%)
A. CeFi/CeDeFi Risks
- Centralization points
- Custody arrangements
- Third-party dependencies
- Operational redundancy
- Emergency procedures

B. Oracle Dependencies
- Oracle manipulation resistance
- Price feed reliability
- Backup oracle systems
- Historical oracle incidents
- Data quality metrics

### 4. External Risk Assessment (5%)
A. Regulatory Risk
- Jurisdictional exposure
- Compliance frameworks
- Regulatory clarity
- Legal structure
- Historical regulatory interactions

B. Social Engineering Risk
- Team security practices
- Access control policies
- Social attack history
- Security awareness training
- Incident response readiness

## Risk-Adjusted Rating Scale

AAA: Exceptional protocol with comprehensive risk mitigation
- Multiple independent security audits with no critical findings
- Proven resistance to all major attack vectors
- Strong regulatory compliance framework
- Decentralized operations with minimal points of failure
- Multiple layers of economic security

AA: Strong protocol with robust risk management
- Regular security audits with minor findings
- Documented resistance to common attack vectors
- Clear regulatory strategy
- Limited centralization risks
- Strong economic security measures

## Risk Multipliers
Each risk category can apply a multiplier to the base rating:
- Critical Risk: -3 rating notches
- High Risk: -2 rating notches
- Medium Risk: -1 rating notch
- Low Risk: No adjustment
- Minimal Risk: +1 rating notch

## Continuous Monitoring Triggers
- Smart contract vulnerability disclosure
- Network attack detection
- Regulatory action
- Economic model stress
- Oracle deviation events
- Cross-chain bridge incidents
- Social engineering attempts
- MEV activity spikes

## Review Framework
- Monthly security metric review
- Quarterly risk assessment update
- Annual comprehensive review
- Real-time monitoring of critical indicators
- Incident-triggered reassessment

## Ozempic Effect
We'll base this upon value flows. Defillama doesn't actually display this. So we'll need to get this data directly from the smart contracts. We can start with Base, Arbitrum, BSC, Optimism and Polygon. 

Let's build a comprehensive framework for tracking the true "Ozempic effect" of L2s on Ethereum. We'll need several interconnected metrics to understand the complete value flow dynamics.

1. Wallet Migration Analysis
- Track addresses that first appeared on Ethereum before a certain date (let's call them "Ethereum Native Wallets")
- Monitor their activity transition to L2s over time
- Analyze their ETH holdings distribution between L1 and L2s
- Calculate the ratio of their transaction activity on L2s versus L1

2. L2 Native User Analysis
- Identify wallets that first appeared on L2s
- Track what percentage never bridge to Ethereum
- Measure their total value held
- Calculate their transaction activity

3. Fee Flow Dynamics
- Track L2 sequencer fees paid back to Ethereum
- Calculate the net fee difference (what these transactions would have cost on L1 versus actual L2 + L1 calldata costs)
- Monitor the ratio of fees paid back to Ethereum versus fees retained by the L2

We could create a composite "Value Migration Score" that looks like:

```python
def calculate_migration_score(l2_data):
    # Value Migration
    eth_native_migration = (
        eth_native_wallets_on_l2 / total_eth_native_wallets *
        eth_value_moved_to_l2 / original_eth_holdings
    )
    
    # Activity Migration
    activity_migration = (
        l2_transactions_by_eth_wallets / 
        (l1_transactions_by_eth_wallets + l2_transactions_by_eth_wallets)
    )
    
    # L2 Native Growth
    l2_native_strength = (
        l2_only_wallets / total_l2_wallets *
        l2_native_value / total_l2_value
    )
    
    # Fee Economics
    fee_efficiency = (
        sequencer_fees_to_ethereum / 
        theoretical_l1_fees_for_same_transactions
    )
    
    return (
        eth_native_migration * 0.3 +
        activity_migration * 0.3 +
        l2_native_strength * 0.2 +
        fee_efficiency * 0.2
    )
```

This would give us a quantitative measure of how effectively an L2 is:
1. Attracting value from Ethereum
2. Generating new value through native users
3. Maintaining a sustainable fee relationship with Ethereum

A true Ozempic L2 should show:
- High migration of ETH native wallets
- Strong L2 native user growth
- Efficient fee generation that still provides meaningful revenue to Ethereum
- Sustained or growing activity ratios over time

Would you like me to elaborate on how we could implement the data collection for any of these metrics, or should we explore additional factors to consider in the scoring?

* Net Value Extraction Rate = (Value Bridged In - Value Bridged Out) / Total Time Period

